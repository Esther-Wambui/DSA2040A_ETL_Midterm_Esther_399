{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68bc1527",
   "metadata": {},
   "source": [
    "## Loading the data and libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcd1b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #requires library\n",
    "#loaded raw and incremental datasets\n",
    "raw_df = pd.read_csv(\"data/raw_data.csv\")\n",
    "inc_df = pd.read_csv(\"data/incremental_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a099ba21",
   "metadata": {},
   "source": [
    "## T1:HANDLING MISSING VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0163897d",
   "metadata": {},
   "source": [
    "### FULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5d1acff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full - Missing Before:\n",
      "quantity      26\n",
      "unit_price    35\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Before\n",
    "print(\"Full - Missing Before:\")\n",
    "print(raw_df[['quantity', 'unit_price']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c5432dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full - Missing After:\n",
      "quantity      0\n",
      "unit_price    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#fill missing quantity and price\n",
    "raw_df['quantity'] = raw_df['quantity'].fillna(raw_df['quantity'].median())#decided to use median for filling missing values\n",
    "raw_df['unit_price'] = raw_df['unit_price'].fillna(raw_df['unit_price'].median())#decided to use median for filling missing values\n",
    "\n",
    "#after\n",
    "print(\"Full - Missing After:\")#this will show the number of missing values after filling\n",
    "print(raw_df[['quantity', 'unit_price']].isnull().sum())#will show the number of missing values after filling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeecdbf",
   "metadata": {},
   "source": [
    "no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02436343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill missing customer name in full dataset\n",
    "raw_df['customer_name'] = raw_df['customer_name'].fillna(\"Unknown\")#decided to fill missing customer names with \"Unknown\" a placeholder value since it has only one missing value\n",
    "raw_df['region'] = raw_df['region'].fillna(\"Unknown\")#also filling missing region with \"Unknown\" since it has 25 missing values and it will not affect the analysis much\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff60b72e",
   "metadata": {},
   "source": [
    "### INCREMENTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26aec250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incremental - Missing Before:\n",
      "customer_name    6\n",
      "quantity         4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Incremental - Missing Before:\")\n",
    "print(inc_df[['customer_name', 'quantity']].isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c03de86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incremental - Missing After:\n",
      "customer_name    0\n",
      "quantity         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill with placeholder\n",
    "inc_df['customer_name'] = inc_df['customer_name'].fillna(\"Unknown\")#decided to fill missing customer names with \"Unknown\" a placeholder value since it won't affect the analysis much\n",
    "inc_df['quantity'] = inc_df['quantity'].fillna(inc_df['quantity'].median())#filled missing quantity with median value\n",
    "\n",
    "print(\"Incremental - Missing After:\")\n",
    "print(inc_df[['customer_name', 'quantity']].isnull().sum())# this will show the number of missing values after filling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28de1e6",
   "metadata": {},
   "source": [
    "no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46af5894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a placeholder for region\n",
    "# Fill missing region in incremental with 'Unknown'\n",
    "inc_df['region'] = inc_df['region'].fillna(\"Unknown\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d529e217",
   "metadata": {},
   "source": [
    "## T2:CONVERTING ORDERDATE TO DATETIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "daff417f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "raw_df['order_date'] = pd.to_datetime(raw_df['order_date'], errors='coerce', dayfirst=True)#converting order_date to datetime format in the raw dataset and used dayfirst=True to ensure correct parsing of dates,the format i want\n",
    "inc_df['order_date'] = pd.to_datetime(inc_df['order_date'], errors='coerce', dayfirst=True)#converting order_date to datetime format in the incremental dataset\n",
    "\n",
    "print(raw_df.dtypes['order_date'])  #should return datetime64[ns]\n",
    "print(inc_df.dtypes['order_date'])  #should return datetime64[ns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d62900",
   "metadata": {},
   "source": [
    "## T3: CONVERTING UNITPRICE TO FLLOAT\n",
    "earlier the unit price was an integer and since price usually contains decimals, hence leaving them as  integers could limit future calculations, even create inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c59ebd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "#converting unit_price to float for consistency in incremental \n",
    "inc_df['unit_price'] = inc_df['unit_price'].astype(float)\n",
    "print(inc_df['unit_price'].dtype)#to confirm the conversion to float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f279d6",
   "metadata": {},
   "source": [
    "## T4:CREATING TOTAL PRICE COLUMN\n",
    "- quantity * unit price = total price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e02b5538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quantity</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quantity  unit_price  total_price\n",
       "0       2.0       500.0       1000.0\n",
       "1       2.0       500.0       1000.0\n",
       "2       2.0       250.0        500.0\n",
       "3       2.0       750.0       1500.0\n",
       "4       3.0       500.0       1500.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quantity</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>300.0</td>\n",
       "      <td>450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quantity  unit_price  total_price\n",
       "0       1.5       900.0       1350.0\n",
       "1       1.0       300.0        300.0\n",
       "2       1.0       600.0        600.0\n",
       "3       1.5       300.0        450.0\n",
       "4       2.0       600.0       1200.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Calculating total price for full dataset\n",
    "raw_df['total_price'] = raw_df['quantity'] * raw_df['unit_price']#calculating total price by multiplying quantity and unit price\n",
    "#Calculating total price for incremental dataset\n",
    "inc_df['total_price'] = inc_df['quantity'] * inc_df['unit_price']#calculating total price by multiplying quantity and unit price\n",
    "\n",
    "display(raw_df[['quantity', 'unit_price', 'total_price']].head())#displaying the first few rows of the raw dataset with quantity, unit price and total price\n",
    "display(inc_df[['quantity', 'unit_price', 'total_price']].head())#displaying the first few rows of the incremental dataset with quantity, unit price and total price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e61c42",
   "metadata": {},
   "source": [
    "## T5: DROPPING ROWS WITH MISSING VALUES(ORDER_ID AND PRODUCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46f3d801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows before drop full: 100\n",
      "rows before drop inc: 10\n",
      "Rows after drop  full: 100\n",
      "Rows after drop inc: 10\n"
     ]
    }
   ],
   "source": [
    "#before dropping rows\n",
    "print(\"rows before drop full:\", len(raw_df))\n",
    "print(\"rows before drop inc:\", len(inc_df))\n",
    "#dropping rows where order_id or product is missing\n",
    "raw_df = raw_df.dropna(subset=['order_id', 'product'])\n",
    "inc_df = inc_df.dropna(subset=['order_id', 'product'])\n",
    "\n",
    "#after dropping rows\n",
    "print(\"Rows after drop  full:\", len(raw_df))\n",
    "print(\"Rows after drop inc:\", len(inc_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a466fe",
   "metadata": {},
   "source": [
    "since we didn't have any rows to drop before and after we move on to the next transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d9f9a4",
   "metadata": {},
   "source": [
    "## T5: REMOVING DUPLICATES\n",
    "full dataset has one duplicate row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e80826a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape before: (100, 8)\n",
      "Full dataset shape after: (99, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"Full dataset shape before:\", raw_df.shape)#show number of rows before removing duplicates\n",
    "\n",
    "raw_df = raw_df.drop_duplicates()# removing duplicates from the raw dataset\n",
    "print(\"Full dataset shape after:\", raw_df.shape)# Show number of rows after\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e443d79b",
   "metadata": {},
   "source": [
    "no duplicates after transformation since we have 99 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b8bd45",
   "metadata": {},
   "source": [
    "## T6:CATEGORIZING REGION AS KNOWN AND UNKNOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5e27046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    region region_status\n",
      "0    South         Known\n",
      "1    North         Known\n",
      "2  Unknown       Unknown\n",
      "3     West         Known\n",
      "4    South         Known\n",
      "    region region_status\n",
      "0  Central         Known\n",
      "1  Central         Known\n",
      "2  Central         Known\n",
      "3  Central         Known\n",
      "4    North         Known\n"
     ]
    }
   ],
   "source": [
    "#fill missing regions that i gave as a placeholder with \"Unknown\" that i gave as a placeholder\n",
    "raw_df['region'] = raw_df['region'].fillna(\"Unknown\")#full dataset\n",
    "inc_df['region'] = inc_df['region'].fillna(\"Unknown\")#incremental dataset\n",
    "\n",
    "#creating region_status column for Known vs Unknown values\n",
    "raw_df['region_status'] = raw_df['region'].apply(lambda x: 'Unknown' if x == 'Unknown' else 'Known')#full dataset\n",
    "inc_df['region_status'] = inc_df['region'].apply(lambda x: 'Unknown' if x == 'Unknown' else 'Known')#incremental dataset\n",
    "# Displaying the first few rows of the region and region_status columns in both datasets\n",
    "print(raw_df[['region', 'region_status']].head())\n",
    "print(inc_df[['region', 'region_status']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c5574a",
   "metadata": {},
   "source": [
    "region status just shows the regions that are known and the ones that are not the missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc7c6f0",
   "metadata": {},
   "source": [
    "## Saving the transformed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34c1300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.to_csv(\"transformed/transformed_full.csv\", index=False)\n",
    "inc_df.to_csv(\"transformed/transformed_incremental.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
